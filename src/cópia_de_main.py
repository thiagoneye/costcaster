# -*- coding: utf-8 -*-
"""Cópia de main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12WQahhN7UahtrEH1MybLZ0VPHi-IsP8y
"""

# Imports

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
from matplotlib.ticker import MultipleLocator

import matplotlib.colors as mcolors

from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor

from statsmodels.tsa.arima.model import ARIMA

# from pmdarima import auto_arima

from typing import List
from typing_extensions import Annotated

import requests
from io import BytesIO

# Data Reading

#df = pd.read_excel("../data/Registro Público de Emissões.xlsx")

URL = "https://raw.githubusercontent.com/thiagoneye/project-ccus_analysis/main/data/Registro%20P%C3%BAblico%20de%20Emiss%C3%B5es.xlsx"
response = requests.get(URL)
df = pd.read_excel(BytesIO(response.content), engine="openpyxl")

# Data Processing

df = df[df["Escopo"] == "Total"]
df.drop(columns=["Setor da Indústria", "Escopo"], inplace=True)

df = df.transpose()
df.columns = df.iloc[0]
df = df[1:].reset_index()
df = df.rename(columns={"index": "Years"})


# ENHANCEMENT Adding constant period from last year reported until current year

new_rows = pd.DataFrame([df.iloc[-1].copy(), df.iloc[-1].copy()]) # copies of 2023
new_rows.iloc[0, new_rows.columns.get_loc("Years")] += 1          # 2024
#new_rows.iloc[1, new_rows.columns.get_loc("Years")] += 2          # 2025
df = pd.concat([df, new_rows], ignore_index=True)                 # extend dataframe

# Company Names

list_of_companies = np.array(["ArcelorMittal", "Votorantim", "Ternium", "Suzano", "CBA", "Intercement"])

# Dataframe Cleaning

for col in list_of_companies:
    df[col] = df[col].astype(float)
    df[col] = df[col].astype(float)

df.iloc[:, 1:] = df.iloc[:, 1:]/1e6

common_year = 2017
df_filtered = df[df.Years >= common_year]

display(df.head())
display(df.info())

# Auxiliary Functions

def applies_power_law(X, y, X_pred):
    X_last = X[-1]
    y_last = y[-1]
    y_pred = y_last * np.exp(np.log(0.91) * (X_pred - X_last) / (2030 - X_last))
    return y_pred


def applies_constant_line(y, X_pred):
    y_last = y[-1]
    y_pred = y_last * np.ones(len(X_pred))
    return y_pred


def get_values(df, company_name):
    X_plot = df.Years.values
    y_plot = df.loc[:, company_name].values
    X_plot = X_plot[~np.isnan(y_plot)]
    y_plot = y_plot[~np.isnan(y_plot)]

    return X_plot, y_plot


def get_blank_values(y_train, X_blank):
    y_last = y_train[-1]
    y_blank = y_last * np.ones(len(X_blank))
    return y_blank


# ENHANCEMENT
def set_weights_jump(data, w: list, commom_range_delimiter=5):
    """Applies a jump as weighting function for the weighted SVR."""

    weights = np.ones(len(data))

    weights[:commom_range_delimiter] = w[0]  # past window weight
    weights[commom_range_delimiter:] = w[1]  # common window weight

    return weights

# ENHANCEMENT
def set_weights_sigmoid(data, common_range_delimiter=5, k=0.05):
    """Applies a sigmoid as weighting function for the weighted SVR."""

    t0 = common_range_delimiter
    weights = 1 / (1 + np.exp(-k * (data - t0)))

    return weights

# ENHANCEMENT
def set_weight_dict(function: str, weights): return {"function": function, "weights": weights}


def generate_weight_pairs_matrix(weight_a, weight_b, n):
    """Generate matrix with weight lists [wa, wb], such that wa + wb = 1 for tests."""

    # Matrix Columns
    col2 = np.linspace(weight_a, weight_b, n)
    col1 = 1 - col2

    # Matrix
    weight_pairs = np.column_stack((col1, col2))

    return weight_pairs



def fit_model(
    X,
    y,
    model: str,
    #weights: Annotated[List[float], "List of past- and common-windou weights [wp, wc]"],
    weighting_params: dict,
    commom_range_delimiter,
):
    """Select models for weighted regression.

    weighting_params: dict with keys
      - "function": "jump" | "sigmoid"
      - "weights":
              if "function" == "jump", must be a list of two floats: e.g. [0.1, 0.9],
                                       which will determine two constant weights
                                       for the past and common windows.
              if "function" == "sigmoid", must be a single float: e.g. k=0.01,
                                       which will control the sigmoid curve steep.

      For any model, the time t=t_b is the cutoff year that closes the past window
      and opens the common window, thus implying that this is the point where the
      weighting function should transition.
    """

    # Weighting
    if not all(key in weighting_params for key in ["function", "weights"]):
      raise ValueError("weighting_params must have keys 'function' and 'weights'.")

    if weighting_params["function"] == "jump":
      weights = set_weights_jump(y, weighting_params["weights"], commom_range_delimiter)

    elif weighting_params["function"] == "sigmoid":
      weights = set_weights_sigmoid(y, commom_range_delimiter, weighting_params["weights"])

    else:
      raise ValueError("Invalid weighting function. Must be 'jump' or 'sigmoid'.")


    # Reshape Input for 2D
    X = X.reshape(-1, 1)

    if model == "poly":
        M = make_pipeline(PolynomialFeatures(degree=4), LinearRegression())
        M.fit(X, y, linearregression__sample_weight=weights)

    elif model == "svr-rbf":
        M = make_pipeline(StandardScaler(), SVR(kernel="rbf"))
        M = SVR(kernel="rbf")
        M.fit(X, y, sample_weight=weights)

    elif model == "svr-poly":
        M = SVR(kernel="poly")
        M.fit(X, y, sample_weight=weights)

    elif model == "rf":
        M = RandomForestRegressor(n_estimators=100)
        M.fit(X, y, sample_weight=weights)

    return M

import matplotlib.pyplot as plt

def add_axvspan_annotation(ax, ta, tb, y_baseline=None):
    """
    Adiciona um axvspan e uma anotação com texto baseado em tb.

    Parâmetros:
    ax: Objeto de eixo do Matplotlib.
    ta: Início do axvspan.
    tb: Fim do axvspan.
    y_baseline: Altura da baseline da anotação (opcional, padrão é o meio do eixo y).

    Retorna:
    None (adiciona axvspan e anotação ao eixo).
    """

    if ta == 2023:
        text = "future domain"
        ax.axvspan(ta, tb, alpha=0.3, color='#ebfbee')
    elif ta == 2017:
        text = "common domain"
        ax.axvspan(ta, tb, alpha=0.3, color='#e7f5ff')
    else:
        text = "past domain"
        ax.axvspan(ta, tb, alpha=0.3, color='#e9ecef')

    x_center = (ta + tb) / 2

    if y_baseline is None:
        y_min, y_max = ax.get_ylim()
        y_baseline = (y_min + y_max) / 2

    ax.annotate(
        text,
        xy=(x_center, y_baseline),
        ha='center',
        va='center',
        bbox=dict(boxstyle='round', facecolor='white', edgecolor="lightgray", alpha=0.8)
    )

def get_ylim(y_min, y_max):
    delta = 0.25*(y_max - y_min)
    return (y_min - delta, y_max + delta)

# Execution

# Set Span Limits

past_range = [2007.5, 2017]
commom_range = [2017, 2023]
blank_range = [2024, 2025]
future_range = [2025, 2030.5]

# Years for Prediction

X_pred = np.array(range(2025, 2031))

# Training Parameters (SVR)

k = 0.05
weights = set_weight_dict("sigmoid", k)
#weights = set_weight_dict("jump", [0.1, 0.9])

windows = 2

# Preparing Variables for Data Export

output = dict()
output["Years"] = X_pred.tolist()

# Start Plot

fig, axs = plt.subplots(2, 3, figsize=(20, 6), constrained_layout=True, sharex=True)
axs = axs.flatten()

colors = {
    "History": mcolors.CSS4_COLORS["darkslategray"],
    "Reference": mcolors.CSS4_COLORS["mediumturquoise"],
    "DBM": mcolors.CSS4_COLORS["goldenrod"],
    "GBM": mcolors.CSS4_COLORS["mediumseagreen"],
    "BAU": mcolors.CSS4_COLORS["indianred"],
}

for company_id, company_name in enumerate(list_of_companies):
    # Data Processing for Training
    X_train, y_train = get_values(df, company_name)
    X_filtered, y_filtered = get_values(df_filtered, company_name)
    commom_range_delimiter = np.where(X_train == common_year)[0][0]

    # Plot (Past and Commom)
    ax = axs[company_id]
    ax.plot(X_train, y_train, "-ok", ms=5, label="history")
    ax.plot(X_filtered[0], y_filtered[0], "*", color="#abb2b9", ms=10, label="$E(t_b)$")
    ax.plot(X_train[-1], y_train[-1], "*", color="#80c6fa", ms=10, label="$E(t_c)$")

    # BAU
    y_pred = applies_constant_line(y_train, X_pred)
    output[f"{company_name} - BAU"] = y_pred.tolist()

    ax.plot(X_pred, y_pred, "--", color=colors["BAU"], label="BAU")

    # DBM
    y_pred = fit_model(
        X_train, y_train, "svr-rbf", weights, commom_range_delimiter
    ).predict(X_pred.reshape(-1, 1))
    y_pred[y_pred < 0] = 0
    output[f"{company_name} - DBM"] = y_pred.tolist()

    ax.plot(X_pred, y_pred, "--", color=colors["DBM"], label="DBM")

    # GBM
    y_pred = applies_power_law(X_filtered, y_filtered, X_pred)
    output[f"{company_name} - GBM"] = y_pred.tolist()

    ax.plot(X_pred, y_pred, "--", color=colors["GBM"], label="GBM")

    # Configure Plot
    ax.xaxis.set_major_locator(MultipleLocator(2))
    ax.set_xlim([2007.5, 2030.5])

    y_min, y_max = min(y_train), max(y_train)
    y_min_lim, y_max_lim = get_ylim(y_min, y_max)

    ax.set_ylim([y_min_lim, y_max_lim])

    add_axvspan_annotation(ax, past_range[0], past_range[1], y_baseline=np.mean([y_min, y_min_lim]))
    add_axvspan_annotation(ax, commom_range[0], commom_range[1], y_baseline=np.mean([y_min, y_min_lim]))
    add_axvspan_annotation(ax, future_range[0], future_range[1], y_baseline=np.mean([y_min, y_min_lim]))

    ax.grid(color='w', axis="y")
    ax.spines['left'].set_visible(False)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)

    ax.legend(loc="upper left", fontsize="small")
    ax.set_title(f"{company_name}")

    if company_id in [0, 3]:
        ax.set_ylabel("$E \\, [MtCO2e]$")

    if company_id >= 3:
        ax.set_xlabel("$t \\, [year]$")

# fig.savefig(f"../img/Forecast.png")

weights

#all(key in weights for key in ["function", "weights"])

# Export Values

output = pd.DataFrame(output)
# output.to_csv("../data/Forecast (MtCO2e).csv")
# output.to_excel("../data/Forecast (MtCO2e).xlsx")